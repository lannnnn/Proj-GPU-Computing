The self developed project for course GPU-Computing
The developing will be split in several steps:

1. finish and full test of the usage of CSR format       passed
2. test the parMetis method as the current baseline - problem: Metis use the different input format(convert); the usage of Metis is much different with our design - the partition number should be fixed at very first and it is using MPI instead of GPU. Temperarily quit this part.
3. develope the sequential code as our first version     passed
4. optimizing... specific methods should be decleared later according to the performance

Usage: 
    for CPU code: in this dir run `make all`
        the target named 'blocktest' will be build in this dir
    for CUDA code: make sure have nvcc compiler. run `make cuda`
        the target named 'block_cuda' and 'ref_block_cuda'

        Usage parameter list:
            -f file direct
            -t tau
            -b block size
            -p SET TO PRINT GROUP INFO
            -m or -e SET MATRIX FILE FORMAT
            -l to iterate tau to find the best block density

The block_cuda use the alg as:
    We treat each group as row, so when two rows is near enough, we produce a new row and disable the original rows. Each thread will take  responsibility of some of the rows. Due to the reason that the size of label(cols message of each row), row number and group size all varies, it's not easy to realize this alg in GPU, mostly due to we will never be sure the final size of group numbers. It's never going to be a proper reduction... So when we have meet large sparse matrix with very low density, the performance will be extremely terrible.... Not make sense to parallelize
    ***NOT PROPERLY WORK SINCE WILL BE REALLY SLOW, SO NOT ADAPTING TO MULTI-BLOCKS***

The ref_block_cuda use the alg as:
    We first choose some of the reference rows(in our case, 4 rows, defined in the cuda_impl.h) that it's far enough to each other. And each thread calculate the distance of the row they are responsible for with these reference rows. If the distance is all larger than tau, then do nothing; but if one of then smaller than tau, add the row into the group which has smallest distance. This algorithm was benefit from parallelize, however not make use of the updated group property since updating the group message is not developed, otherwise huge overhead should be involved due to synchronization issue... 

To run the code in cluster, referring to the script 'ref_test.sh'. This script can be directly use in MARZOLA

To change the referring row size, change the value of 'ref_size' in the file cuda_impl.cuh
To change the rows per threads, change the value of 'row_size' in the file cuda_impl.cuh

------------------------------------------------------------------------------------------------------------------

Updated 04/08 
If do not make usage of the block boundary message, the result of reordering may not give benefits for different block size.
Example: we have
 line1  1 0 0 0 1 0 0 0
 line2  0 0 0 0 1 0 0 0
 line3  0 0 0 0 0 1 1 1
When considering the block size = (4,4), according to Jaccard distance, line2 will be groupped with line1. But obviously, it will perform worse, but should be groupped with line3.
Plan to make usage of the block boundary message.... 
Idea: instead of using a whole line message to calculate the Jaccard distance, using a "mask" which will present the block boundary message 
    start processing the colomn index when reading the matrix
    This idea can also be called compress the matrix, and to gain benefits, we should decide a very small tau
    Can be further developed to combine with the non masked case
    Can be further developed to adapting the multi-GPU idea as pre-partition

Also, if a group do not have the # rows which can be devide by block col, it means there be blocks combined by two different groups. It's not good for reordering...
Idea: filling the group with the empty rows so no block will be combine by different groups... 
------------------------------------------------------------------------------------------------------------------

DATASET STATUS:(cluster queue time limit to 5 minutes)

1. the complexity is bring from [1] O(1) find the refering row(s) [2] comparing with other rows, each comparation will have at largest 2*min(rank1,rank2) times comparing, so at worst case will have the complexity of nrows*(nrows-1)*nnz
2. tau and ref_thread_size(in fact another alg) will effect the execution time - the larger tau/ref_thread_size, the longger time spend
2*. decreasing tau do not really means the new density will increasing - but with the idea in Updated 24/06, the density should increase in theory..
3. memory boundary is for the size of CSR matrix, not yet met. The boundary (global memory size of CPU/GPU(A30)) is for((nrows+1) + ncols) * sizeof(int)[CSR] + (nrows + ref_thread_size) * sizeof(int)[Msg use for calculation] + sizeof(float)[tau]

result refer to result_collect.txt
------------------------------------------------------------------------------------------------------------------

finding the suitable tau

